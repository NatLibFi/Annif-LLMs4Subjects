Stochastic Approximation and Recursive Algorithms and Applications
This revised and expanded second edition presents a thorough development of the modern theory of stochastic approximation or recursive stochastic algorithms for both constrained and unconstrained problems. There is a complete development of both probability one and weak convergence methods for very general noise processes. The proofs of convergence use the ODE method, the most powerful to date. The assumptions and proof methods are designed to cover the needs of recent applications. The development proceeds from simple to complex problems, allowing the underlying ideas to be more easily understood. Rate of convergence, iterate averaging, high-dimensional problems, stability-ODE methods, two time scale, asynchronous and decentralized algorithms, state-dependent noise, stability methods for correlated noise, perturbed test function methods, and large deviations methods are covered. Many motivating examples from learning theory, ergodic cost problems for discrete event systems, wireless communications, adaptive control, signal processing, and elsewhere illustrate the applications of the theory.
Introduction: Applications and Issues -- Applications to Learning, Repeated Games, State Dependent Noise, and Queue Optimization -- Applications in Signal Processing, Communications, and Adaptive Control -- Mathematical Background -- Convergence with Probability One: Martingale Difference Noise -- Convergence with Probability One: Correlated Noise -- Weak Convergence: Introduction -- Weak Convergence Methods for General Algorithms -- Applications: Proofs of Convergence -- Rate of Convergence -- Averaging of the Iterates -- Distributed/Decentralized and Asynchronous Algorithms.
