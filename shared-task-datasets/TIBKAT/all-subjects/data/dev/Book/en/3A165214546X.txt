Essential Statistical Inference : Theory and Methods
This book is for students and researchers who have had a first year graduate level mathematical statistics course. It covers classical likelihood, Bayesian, and permutation inference; an introduction to basic asymptotic distribution theory; and modern topics like M-estimation, the jackknife, and the bootstrap. R code is woven throughout the text, and there are a large number of examples and problems. An important goal has been to make the topics accessible to a wide audience, with little overt reliance on measure theory. A typical semester course consists of Chapters 1-6 (likelihood-based estimation and testing, Bayesian inference, basic asymptotic results) plus selections from M-estimation and related testing and resampling methodology. Dennis Boos and Len Stefanski are professors in the Department of Statistics at North Carolina State. Their research has been eclectic, often with a robustness angle, although Stefanski is also known for research concentrated on measurement error, including a co-authored book on non-linear measurement error models. In recent years the authors have jointly worked on variable selection methods. .
Roles of Modeling in Statistical Inference.- Likelihood Construction and Estimation.- Likelihood-Based Tests and Confidence Regions.- Bayesian Inference.- Large Sample Theory: The Basics.- Large Sample Results for Likelihood-Based Methods.- M-Estimation (Estimating Equations).- Hypothesis Tests under Misspecification and Relaxed Assumptions .- Monte Carlo Simulation Studies .- Jackknife.- Bootstrap.- Permutation and Rank Tests.- Appendix: Derivative Notation and Formulas.- References.- Author Index.- Example Index -- R-code Index -- Subject Index.
