Complex Event Processing : Komplexe Analyse von massiven Datenströmen mit CEP
Motivation: Datenströme in vernetzten Systemen -- Complex Event Processing im Überblick -- Sprachkonzepte zur Ereignisverarbeitung -- Fallstudie: Überwachung eines industriellen M2M-Systems -- Stand der Entwicklung und Ausblick.
Ralf Bruns und Jürgen Dunkel bieten eine kompakte Einführung in die Grundprinzipien von Complex Event Processing (CEP), das eine extrem leistungsfähige Softwaretechnologie zur systematischen Analyse von massiven Datenströmen in Echtzeit darstellt. Die Autoren stellen die wesentlichen Sprachkonzepte der Ereignisverarbeitung Schritt für Schritt vor. Eine Fallstudie aus dem M2M-Bereich verdeutlicht die praktische Anwendung von CEP. Moderne Unternehmen stehen vor der Herausforderung mit immer größeren Datenmengen umgehen zu müssen. Neben immensen statischen Datenbeständen ist es entscheidend, auch kontinuierlich eintreffende Datenströme effizient zu nutzen, um geschäftliche Entscheidungen situationsabhängig treffen zu können. Mit CEP ist es möglich, hochfrequente Datenströme intelligent zu analysieren und daraus zeitnah operative Unternehmensentscheidungen abzuleiten. CEP steht für eine neue Qualität von Unternehmensanwendungen – agil und effizient. Der Inhalt · Motivation: Datenströme in vernetzten Systemen · Complex Event Processing im Überblick · Sprachkonzepte zur Ereignisverarbeitung · Fallstudie: Überwachung eines industriellen M2M-Systems Die Zielgruppen · Dozierende und Studierende der Informatik und verwandter Fachgebiete · Praktiker in der Softwareentwicklung, die einen Einblick in die intelligente Echtzeitanalyse von massiven Datenströmen erhalten wollen. Die Autoren Prof. Dr. Ralf Bruns und Prof. Dr. Jürgen Dunkel sind Professoren für Softwareentwicklung an der Hochschule Hannover.
