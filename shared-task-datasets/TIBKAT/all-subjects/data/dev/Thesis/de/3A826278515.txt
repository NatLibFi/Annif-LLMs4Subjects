Robust peer prediction mechanisms
Zusammenfassung: Diese Dissertation beschäftigt sich mit Peer-Prediction-Mechanismen, welche Nutzern von Online-Systemen einen Anreiz geben, private Meinungen oder Erfahrungen ehrlich abzugeben. Der ursprüngliche Peer-Prediction-Mechanismus [Miller-et-al., 2005] vergleicht dazu die Antworten von zwei Nutzern miteinander und bezahlt diese anhand einer Zahlungsregel, welche sicherstellt, dass die Übermittlung von ehrlichen Informationen ein spieltheoretisches Gleichgewicht bildet. Das Problem dieses Mechanismus ist, dass er für die Praxis zu hohe Anforderungen an das gemeinsame Wissen (common knowledge) der Nutzer stellt.In dieser Dissertation entwickle ich Peer-Prediction-Mechanismen mit stark abgeschwächten Annahmen an das gemeinsame Wissen, was eine praktische Anwendung dieser Mechanismen ermöglicht. Ich entwickle zuerst das "Robust Bayesian Truth Serum" (RBTS), welches, zusätzlich zur Meinung oder Erfahrung des Nutzers, auch eine probabilistische Vorhersage der übermittelten Erfahrungen anderer Nutzer abfragt. Im Gegensatz zum Original-BTS-Mechanismus ist RBTS bereits ab drei Nutzern anreizkompatibel und kann außerdem so konfiguriert werden, dass die Zahlungen an die Nutzer nie negativ sind. Aufbauend auf RBTS schwäche ich die Anforderungen an gemeinsames Wissen weiter ab und entwickle einen anreizkompatiblen Mechanismus, in dem jeder Nutzer nicht nur subjektive Erfahrungen macht, sondern auch ein subjektives Modell der Wirklichkeit hat. Wie bei RBTS müssen die Nutzer sowohl die eigentliche Information als auch eine Vorhersage über die von anderen Nutzern abgegebenen Informationen übermitteln. Im Unterschied zu RBTS kann der Mechanismus dafür jedoch nicht auf die von anderen Nutzern übermittelten probabilistischen Vorhersagen zurückgreifen. Während alle diese Mechanismen den Nutzern Anreize geben, Informationen ehrlich zu übermitteln, müssen Nutzer diese Informationen in vielen Anwendungen, insbesondere im "crowdsourcing", jedoch erst beschaffen. Ich entwickle hierfür einen Mechanismus, der den Nutzern einen Anreiz gibt, den für die Informationsbeschaffung nötigen Aufwand zu betreiben. Nutzer, die sich bei einer Antwort nicht sicher sind, gibt der Mechanismus darüber hinaus einen Anreiz zu passen und keine Bewertung abzugeben
Zusammenfassung: This thesis addresses the challenge of peer prediction, which seeks to elicit private information from rational agents without the requirement that ground truth is eventually revealed. The classical peer prediction method provides a solution to the peer prediction challenge. It compares the reported information of an agent with the reported information of another agent, and computes a payment rule that implements truth revelation in a strategic equilibrium. However, the algorithm computing the payments critically depends on the method's assumption that all agents share the same prior beliefs and that the algorithm ("mechanism") knows these beliefs.In this thesis, I relax this common knowledge assumption. I first design the "Robust Bayesian Truth Serum" (RBTS), which asks agents for two types of reports, the report of the private information it is interested in and a prediction report corresponding to an agent's belief about the private information of other agents. RBTS dispenses with the assumption that the agents' prior beliefs need to be known to compute the payments. It does, however, still rely on the agents sharing the same prior beliefs. My second contribution is the design of subjective-prior peer prediction mechanisms, which further reduce the assumption of common knowledge. As in RBTS, they do not require knowledge of the agents' prior beliefs. Moreover, they allow the agents' prior beliefs to be subjective, i.e. different from one another. My third contribution is the study of effort-incentivizing peer prediction. In many applications of interest, the information that seeks to be elicited first needs to be acquired. When this information acquisition requires costly effort, agents may have an incentive to avoid it and choose to guess instead. Addressing this problem, I suggest payments, where only agents with good enough information have an incentive to participate in the mechanism. Agents not investing effort and agents with low quality, choose to pass, effectively self-selecting according to quality
