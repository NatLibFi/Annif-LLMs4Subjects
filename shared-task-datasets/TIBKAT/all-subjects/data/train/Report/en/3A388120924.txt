Stochastic optimization methods
Optimization problems arising in practice involve random model parameters. For the computation of robust optimal solutions, i.e., optimal solutions being insensitive with respect to random parameter variations, appropriate deterministic substitute problems are needed. Based on the probability distribution of the random data, and using decision theoretical concepts, optimisation problems under stochastic uncertainty are converted into appropriate deterministic substitute problems. Due to the occurring probabilities and expectations, hence, multiple integrals, approximative solution techniques must be applied. Several deterministic and stochastic approximation methods are provided: Taylor expansion methods, regression and response surface methods (RSM), probability inequalities, First order reliability methods (FORM), convex approximation/deterministic descent directions/efficient points, stochastic gradient methods, stochastic approximation procedures, differentiation formulas for probabilities and expectations. The mathematical properties of the approximative problems and iterative solution procedures (e.g. rate of convergence) are described. TOC:Basic Stochastic Optimization Methods: Decision/Control Under Stochastic Uncertainty.- Deterministic Substitute Problems in Optimal Decision Under Stochastic Uncertainty.- Differentiation Methods: Differentiation Methods for Probability and Risk Functions.- Deterministic Descent Directions: Deterministic Descent Directions and Efficient Points.- Semi-Stochastic Approximation Methods: RSM-Based Stochastic Gradient Procedures.- Stochastic Approximation Methods with Different Error Variances.- Technical Applications: Approximation of the Probability of Failure/Survival
