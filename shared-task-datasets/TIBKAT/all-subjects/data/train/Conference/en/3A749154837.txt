Optimal Control, Stabilization and Nonsmooth Analysis
This edited book contains selected papers presented at the Louisiana Conference on Mathematical Control Theory (MCT'03), which brought together over 35 prominent world experts in mathematical control theory and its applications. The book forms a well-integrated exploration of those areas of mathematical control theory in which nonsmooth analysis is having a major impact. These include necessary and sufficient conditions in optimal control, Lyapunov characterizations of stability, input-to-state stability, the construction of feedback mechanisms, viscosity solutions of Hamilton-Jacobi equations, invariance, approximation theory, impulsive systems, computational issues for nonlinear systems, and other topics of interest to mathematicians and control engineers. The book has a strong interdisciplinary component and was designed to facilitate the interaction between leading mathematical experts in nonsmooth analysis and engineers who are increasingly using nonsmooth analytic tools
