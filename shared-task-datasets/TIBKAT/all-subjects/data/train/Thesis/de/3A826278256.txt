Camera-based humanoid robot navigation
Zusammenfassung: Im letzten Jahrzehnt stieg die Anzahl der Roboter, die im Haushalt eingesetzt werden, deutlich an. Dabei dominieren zwei Arten von Robotern, nämlich solche die Staubsaugen und solche, die Rasen mähen. Dass gerade diese beiden Typen so verbreitet sind, mag daran liegen, dass diese Aufgaben anhand relativ simpler Durchführungsstrategien umgesetzt werden können. Ein Roboter etwa, der mit konstanter Geschwindigkeit durch einen Raum fährt und dabei zufällig seine Richtung ändert, hat irgendwann jede erreichbare Fläche desselben überquert. Natürlich gibt es mittlerweile auch Roboter, die ihre Aufgabe zielgerichteter erledigen, zum Beispiel indem sie ihre Position innerhalb eines Raumes bestimmen und so den Bewegungsablauf optimieren. Dennoch sind solche Roboter in ihrer Funktionsvielfalt sehr eingeschränkt und weit von dem entfernt, was man aus der Fiktion als Service-Roboter kennt.Wir hätten gerne einen Roboter, der vielfältige Aufgaben im Haushalt übernimmt - etwa Wäsche aufhängen, Geschirr waschen oder eben auch den Boden saugen. Er soll uns im Alltag zur Hand gehen und dabei auch anspruchsvolle Aufgaben erledigen. Vor dem Hintergrund von Katastrophen wie der des havarierten Atomkraftwerks in Fukushima stellt sich zudem die Frage, ob Roboter nicht auch in solchen Szenarien eingesetzt werden könnten, um Schlimmeres zu verhindern und Menschenleben zu schützen. Denn ein Roboter lässt sich ersetzen, ein Mensch dagegen nicht. So könnten Roboter in Gefahrensituationen eingesetzt werden und beispielsweise wichtige Informationen über den Zustand beschädigter Gebäude liefern, Wege freiräumen, Feuer löschen oder Notstrom-Aggregate in Stand setzen. Angesichts dieser Möglichkeiten ist es sinnvoll, sich mit der Weiterentwicklung von autonomen Robotern zu beschäftigen. Hierzu leistet diese Arbeit einen wichtigen Beitrag.Nach der Katastrophe von Fukushima wurde die Robotics Challenge von der US-amerikanischen DARPA (Defense Advanced Research Projects Agency) ins Leben gerufen. Der Wettkampf soll die Entwicklung von Robotern für den Einsatz in Katastrophenszenarien fördern. Dabei richten sich die Anforderungen an die Roboter an Tätigkeiten aus, die in solchen Szenarien von Bedeutung sind. Dazu gehört es etwa, unwegsames Gelände zu überschreiten, Trümmerteile wegzuräumen, Leitern zu erklimmen, oder gar Wände mit entsprechendem Werkzeug einzureißen. Die hohe Komplexität der genannten Au ...
Zusammenfassung: Humanoid robots possess unique locomotive and manipulation capabilities which makes them predestined as assistants in households or even in disaster scenarios. Their legs allow them to walk across rough terrain and clutter, climb elevations, or pass narrow passages. At the same time, with their arms, they could deliver objects, remove debris, or even use power tools to cut through walls. However, to enable this kind of behavior, novel navigation techniques are required that exploit the special capabilities of humanoids. One of the great challenges in navigation is that a robot always acts under uncertainty. It possesses only imperfect knowledge about itself and its environment, yet this knowledge is fundamental. Motions and observations are affected by noise and need to be handled appropriately. Data has to be associated in the presence of ambiguities to obtain consistent representations of the environment. For humanoid robots, the problem aggravates as the kinematic complexity that needs to be handled is higher compared to wheeled robots. The shaking motion of the humanoids adds further errors to the sensor data, making it harder to interpret. Additional constraints like balance and payload need to be considered. In this thesis, we present novel methods that contribute to the development of autonomous humanoid robots. Hereby, we focus on cameras as primary sensor. First, we describe a method to self-calibration of the robot's kinematic model. Hereby, our approach automatically selects appropriate calibration postures. Further, we present a method to identify safe areas for the robot to step onto based on self-supervised classification of camera images. Additionally, we describe an integrated navigation system for robots equipped with depth cameras. The approach estimates the robot's 6D pose within a map, constructs a volumetric representation of the unknown parts of the environment and plans collision-free paths to a target location. We introduce extensions that allow navigation in challenging, cluttered scenarios based on anytime footstep planning. Thereby we enable the robot to step over or onto obstacles and traverse narrow passages. Finally, we demonstrate a method that enables accurate manipulation by tracking the pose of objects in the camera images. All of our techniques are implemented and thoroughly evaluated on a Nao humanoid. Our contributions advance the state-of-the-art in humanoid robot navigation and enable autonomous navig ...
