Frequency, chunks and hesitations : a usage-based analysis of chunking in English
Zusammenfassung: This book addresses the questions in how far the frequency with which speakers use sequences of words influences how their minds store and process these strings and how such effects can best be modelled. The studies compiled in the book start out from the usage-based tenet that language use shapes its mental representation. They focus on various types of multi-word strings, such as 'I don’t know' or 'a lot of', and investigate how their mental representation changes depending on how frequently they are used. Two detailed sets of analyses test whether the more often sequences are used, the more unit-like or ‘chunked’ they become and furthermore address a number of theoretical and technical questions which mainly arise from details of Bybee’s (2010) model of the mind and her understanding of chunking.  The author is the first to present a large-scale corpus analysis which utilises the placement of hesitations in spoken American English – as represented by the Switchboard NXT corpus – together with the innovative statistical procedures of Classification and Regression Trees and random forests
