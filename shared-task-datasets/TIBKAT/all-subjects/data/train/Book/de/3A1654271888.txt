Datenqualität in Stichprobenerhebungen : Eine verständnisorientierte Einführung in Stichprobenverfahren und verwandte Themen
Vom Teil aufs Ganze – Einführung in die Stichprobentheorie -- Die Mutter aller Zufallsstichprobenverfahren – Die uneingeschränkte Zufallsauswahl -- Es geht auch anders – Weitere Schätzmethoden -- Zerlegen macht’s genauer – Die geschichtete uneingeschränkte Zufallsauswahl -- Nahe Liegendes gemeinsam erheben spart Geld – Die uneingeschränkte Klumpenauswahl -- Nahe beisammen und doch auseinander – Die zweistufige uneingeschränkte Zufallsauswahl -- Grenzt an Zauberei – Die größenproportionale Zufallsauswahl -- Welcher Zweck heiligt solche Mittel? - Die nichtzufälligen Auswahlen -- Anhang -- Literatur -- Sachverzeichnis.
Resultate von Stichprobenerhebungen in Bereichen wie der empirischen Sozial- oder Wirtschaftsforschung, der offiziellen Statistik oder der kommerziellen Markt- und Meinungsforschung finden sich tagtäglich in Zeitungen oder Nachrichtensendungen. Die statistische Stichprobentheorie liefert für diese Ergebnisse den wissenschaftlichen Unterbau, indem sie sich damit auseinandersetzt, wie die Auswahl der Stichprobe zu erfolgen hat und wie von deren Beobachtungen auf die Gesamtheit geschlossen werden kann. Die Kernfragen in Hinblick auf die Qualität von Stichprobenerhebungen sind dabei: Wie stark schwanken die Stichprobenergebnisse und wodurch lässt sich deren Genauigkeit beeinflussen? Das Buch bietet eine verständnis- und anwendungsorientierte Einführung in verschiedene Stichprobendesigns, bestehend aus Auswahlverfahren und Schätzmethodik. Das Methodenverständnis wird unterstützt durch einfach nachvollziehbare und gerade dadurch besonders förderliche Beispiele. Dabei werden auch andere praxisrelevante Aspekte, welche sich auf die Qualität der gezogenen Schlussfolgerungen auswirken, nicht ausgeklammert: Behandelt werden unter anderem die Nonresponse-Thematik sowie die Anwendung von nichtzufälligen Auswahltechniken wie dem Quotenverfahren. Der Autor Andreas Quatember ist außerordentlicher Professor an der Abteilung für Datengewinnung und Datenqualität des Instituts für Angewandte Statistik (IFAS) der Johannes Kepler Universität Linz (Österreich). Er lehrt Statistik und ist Autor der Bücher Statistik ohne Angst vor Formeln und Statistischer Unsinn: Wenn Medien an der Prozenthürde scheitern.
