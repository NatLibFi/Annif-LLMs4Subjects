Stochastic Optimal Control in Infinite Dimension : Dynamic Programming and HJB Equations
Providing an introduction to stochastic optimal control in infinite dimension, this book gives a complete account of the theory of second-order HJB equations in infinite-dimensional Hilbert spaces, focusing on its applicability to associated stochastic optimal control problems. It features a general introduction to optimal stochastic control, including basic results (e.g. the dynamic programming principle) with proofs, and provides examples of applications. A complete and up-to-date exposition of the existing theory of viscosity solutions and regular solutions of second-order HJB equations in Hilbert spaces is given, together with an extensive survey of other methods, with a full bibliography. In particular, Chapter 6, written by M. Fuhrman and G. Tessitore, surveys the theory of regular solutions of HJB equations arising in infinite-dimensional stochastic control, via BSDEs. The book is of interest to both pure and applied researchers working in the control theory of stochastic PDEs, and in PDEs in infinite dimension. Readers from other fields who want to learn the basic theory will also find it useful. The prerequisites are: standard functional analysis, the theory of semigroups of operators and its use in the study of PDEs, some knowledge of the dynamic programming approach to stochastic optimal control problems in finite dimension, and the basics of stochastic analysis and stochastic equations in infinite-dimensional spaces
Preface -- 1.Preliminaries on stochastic calculus in infinite dimensions -- 2.Optimal control problems and examples -- 3.Viscosity solutions -- 4.Mild solutions in spaces of continuous functions -- 5.Mild solutions in L2 spaces -- 6.HJB Equations through Backward Stochastic Differential Equations (by M. Fuhrman and G. Tessitore) -- Appendix A, B, C, D, E -- Bibliography
