Ensemble learning for AI developers : learn bagging, stacking, and boosting methods with use cases
Chapter 1: Why Ensemble Techniques Are Needed -- Chapter 2: Mix Training Data -- Chapter 3: Mix Models -- Chapter 4: Mix Combinations -- Chapter 5: Use Ensemble Learning Libraries -- Chapter 6: Tips and Best Practices.-.
Use ensemble learning techniques and models to improve your machine learning results. Ensemble Learning for AI Developers starts you at the beginning with an historical overview and explains key ensemble techniques and why they are needed. You then will learn how to change training data using bagging, bootstrap aggregating, random forest models, and cross-validation methods. Authors Kumar and Jain provide best practices to guide you in combining models and using tools to boost performance of your machine learning projects. They teach you how to effectively implement ensemble concepts such as stacking and boosting and to utilize popular libraries such as Keras, Scikit Learn, TensorFlow, PyTorch, and Microsoft LightGBM. Tips are presented to apply ensemble learning in different data science problems, including time series data, imaging data, and NLP. Recent advances in ensemble learning are discussed. Sample code is provided in the form of scripts and the IPython notebook. You will: Understand the techniques and methods utilized in ensemble learning Use bagging, stacking, and boosting to improve performance of your machine learning projects by combining models to decrease variance, improve predictions, and reduce bias Enhance your machine learning architecture with ensemble learning.
