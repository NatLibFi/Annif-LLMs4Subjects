Matrix Tricks for Linear Statistical Models : Our Personal Top Twenty
In teaching linear statistical models to first-year graduate students or to final-year undergraduate students there is no way to proceed smoothly without matrices and related concepts of linear algebra; their use is really essential. Our experience is that making some particular matrix tricks very familiar to students can substantially increase their insight into linear statistical models (and also multivariate statistical analysis). In matrix algebra, there are handy, sometimes even very simple “tricks” which simplify and clarify the treatment of a problem—both for the student and for the professor. Of course, the concept of a trick is not uniquely defined—by a trick we simply mean here a useful important handy result. In this book we collect together our Top Twenty favourite matrix tricks for linear statistical models.
Introduction -- Easy Column Space Tricks -- Easy Projector Tricks -- Easy Correlation Tricks -- Generalized Inverses in a Nutshell -- Rank of the Partitioned Matrix and the Matrix Product -- Rank Cancellation Rule -- Sum of Orthogonal Projector -- Minimizing cov(y - Fx) -- BLUE -- General Solution to AYB = C -- Invariance with Respect to the Choice of Generalized Inverse -- Block-Diagonalization and the Schur Complement -- Nonnegative Definiteness of a Partitioned Matrix -- The Matrix M -- Disjointness of Column Spaces -- Full Rank Decomposition -- Eigenvalue Decomposition -- Singular Value Decomposition -- The Cauchy-Schwarz Inequality -- Notation -- References -- Author Index -- Subject Index.
