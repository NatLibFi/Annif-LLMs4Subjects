Infinite Horizon Optimal Control : Deterministic and Stochastic Systems
This book presents a systematic account of the development of optimal control problems defined on an unbounded time interval - beginning primarily with the work of the early seventies to the present. The first five to six chapters provide a good introduction to infinite horizon control theory and require only a minimal knowledge of mathematical control theory. The remainder of the book considers extensions of the previous chapters to a variety of control systems, including Distributed Parameter Systems, Stochastic Control Systems and Hereditary Systems. Consequently these chapters require more sophistication. Throughout the book it is possible to distinguish three categories of research: - The extension of the classical necessary conditions to various weaker types of optimality (e.g., overtaking optimality); - The discussion of various sufficient conditions and verification theorems for the various types of optimality; - The discussion of existence theorems for the various types of optimality. The common link between these categories is the "Turnpike Property" and the notion of "Reduction to Finite Costs". Once these properties are established for a given control system, it is possible to begin investigating the issues described in the above three categories
