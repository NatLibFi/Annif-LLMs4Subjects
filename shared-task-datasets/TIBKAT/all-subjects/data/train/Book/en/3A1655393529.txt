A Distribution-Free Theory of Nonparametric Regression
Why Is Nonparametric Regression Important? -- How to Construct Nonparametric Regression Estimates? -- Lower Bounds -- Partitioning Estimates -- Kernel Estimates -- k-NN Estimates -- Splitting the Sample -- Cross-Validation -- Uniform Laws of Large Numbers -- Least Squares Estimates I: Consistency -- Least Squares Estimates II: Rate of Convergence -- Least Squares Estimates III: Complexity Regularization -- Consistency of Data-Dependent Partitioning Estimates -- Univariate Least Squares Spline Estimates -- Multivariate Least Squares Spline Estimates -- Neural Networks Estimates -- Radial Basis Function Networks -- Orthogonal Series Estimates -- Advanced Techniques from Empirical Process Theory -- Penalized Least Squares Estimates I: Consistency -- Penalized Least Squares Estimates II: Rate of Convergence -- Dimension Reduction Techniques -- Strong Consistency of Local Averaging Estimates -- Semirecursive Estimates -- Recursive Estimates -- Censored Observations -- Dependent Observations.
The regression estimation problem has a long history. Already in 1632 Galileo Galilei used a procedure which can be interpreted as ?tting a linear relationship to contaminated observed data. Such ?tting of a line through a cloud of points is the classical linear regression problem. A solution of this problem is provided by the famous principle of least squares, which was discovered independently by A. M. Legendre and C. F. Gauss and published in 1805 and 1809, respectively. The principle of least squares can also be applied to construct nonparametric regression estimates, where one does not restrict the class of possible relationships, and will be one of the approaches studied in this book. Linear regression analysis, based on the concept of a regression function, was introduced by F. Galton in 1889, while a probabilistic approach in the context of multivariate normal distributions was already given by A. B- vais in 1846. The ?rst nonparametric regression estimate of local averaging type was proposed by J. W. Tukey in 1947. The partitioning regression - timate he introduced, by analogy to the classical partitioning (histogram) density estimate, can be regarded as a special least squares estimate.
