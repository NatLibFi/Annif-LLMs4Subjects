Mensch-Technik-Interaktion mittels Freiraumgesten
Mit Industrie 4.0 gewinnt die Mensch-Technik-Interaktion deutlich an Stellenwert. Sollen Mensch und Maschine gemeinsam arbeiten, dann sind alternative Interaktionsformen zu entwickeln. Erfolgreiche Kommunikation bedeutet, dass beide Kommunikationspartner zum Kommunikationsende den gleichen Informationsstand haben. Die natürliche, menschliche Kommunikation findet auf verschiedenen Ebenen (z.B. visuell und akustisch) statt, welche zusammengehörig gedeutet werden. An der redebegleitenden Zeigegeste lässt sich das Zusammenspiel von gesprochenem Wort, ausgeführter Zeigegeste und kognitiver Leistung des Empfängers gut erkennen. Der "grüne Ordner da drüben" fordert vom Empfänger neben der rein sensorischen Aufgabe des Hörens und Sehens die zusätzliche, wissensbasierte Verarbeitung von "grün" und "Ordner". Mit all diesen Informationen erreicht die gestenunterstützte Mensch-Mensch-Kommunikation eine Erkennungsrate von annähernd 100 %. Sollen für die Mensch-Technik-Kommunikation "Zeigegesten" verwendet werden, sind die zusätzlichen Kontext-Informationen z.Z. für die technische Auswertung noch nicht verfügbar. Daher wurden Beschreibungen der Zeigegeste entwickelt und evaluiert, mit denen bereits ohne Interpretation der Kontextinformation eine Gesamterkennungsrate von über 85 % realisiert werden kann. Ausgehend von dem Nutzerverständnis - Zeigen wird als statische Geste verstanden - wurde eine technisch nutzbare Beschreibung entwickelt. Diese, nur die Körperpose des Zeigens auswertend, erreicht bei der Evaluation eine Erkennungsrate von ca. 50 %. Sie ließ sich bereits im Rahmen eines Forschungsprojektes erfolgreich in die Praxisübertragen. Auf Grundlage eines Phasenmodells der Gestenausführung wurden zwei weitere Beschreibungen entwickelt. Bei diesen wird der gesamte Gestenzyklus aus Einleitung, Hauptteil, Haltephase und Ausleitung betrachtet. Mit den Daten der für die Evaluation eingesetzten Kinect® 2 konnten mit den erweiterten Phasendefinitionen Erkennungsraten von über 85 % realisiert werden. Für eine Verbesserung der Erkennungsrate ist es zukünftig notwendig, weitere Gesten wie das "Heranwinken" zu beschreiben, um sie vom "Zeigen" abzugrenzen. Zusätzlich muss das Zeigeziel erkannt und anhand der Kontextinformation überprüft werden können.
