Multiple classifier systems in human-computer interaction
Making the interaction of human subjects with technical systems more intuitive is a quickly emerging interdisciplinary field of research. One important aspect of this field is the surveillance of the user by the respective system and thus enabling it to estimate distinct user states. The automatic recognition of user states in human-computer interaction poses a great challenge to statistical pattern recognition for several reasons: The measurements of the different sensors are inherently heterogeneous in their technical properties, for example considering sample rates, range of values or resolution. Another important aspect is the fact that the true state of a subject is generally not entirely observable from the outside, which makes the design of corpora that study human-computer interaction extremely difficult. This leads in many cases to weakly or subjectively defined class labels by either using human test persons that annotate the collected material manually or by using externally triggered stimuli that are designed to elicit distinct predefined states. In order to approach the recognition of user states in human-computer interaction, the multi-modal and the temporal properties of the application are exploited in this work. For this purpose, different information fusion architectures based on multiple classifier system approaches and temporal integration techniques are introduced and discussed. Besides this, the incorporation of unlabeled data into the training of the classifier is a compelling issue since one is generally short of training data as described earlier. This work will introduce a partially supervised learning approach, that combines unsupervised and supervised learning in order to extend the amount of usable data. Finally, the problem of imbalanced class distributions is tackled by a class weighting mechanism in the training of support vector machines, which increases the loss for the underrepresented class.
