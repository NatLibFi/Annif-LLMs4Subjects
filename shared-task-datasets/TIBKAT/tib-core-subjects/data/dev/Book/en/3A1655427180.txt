Asymptotic Optimal Inference for Non-ergodic Models
This monograph contains a comprehensive account of the recent work of the authors and other workers on large sample optimal inference for non-ergodic models. The non-ergodic family of models can be viewed as an extension of the usual Fisher-Rao model for asymptotics, referred to here as an ergodic family. The main feature of a non-ergodic model is that the sample Fisher information, appropriately normed, converges to a non-degenerate random variable rather than to a constant. Mixture experiments, growth models such as birth processes, branching processes, etc. , and non-stationary diffusion processes are typical examples of non-ergodic models for which the usual asymptotics and the efficiency criteria of the Fisher-Rao-Wald type are not directly applicable. The new model necessitates a thorough review of both technical and qualitative aspects of the asymptotic theory. The general model studied includes both ergodic and non-ergodic families even though we emphasise applications of the latter type. The plan to write the monograph originally evolved through a series of lectures given by the first author in a graduate seminar course at Cornell University during the fall of 1978, and by the second author at the University of Munich during the fall of 1979. Further work during 1979-1981 on the topic has resolved many of the outstanding conceptual and technical difficulties encountered previously. While there are still some gaps remaining, it appears that the mainstream development in the area has now taken a more definite shape.
0. An Over-view -- 1. Introduction -- 2. The Classical Fisher-Rao Model for Asymptotic Inference -- 3. Generalisation of the Fisher-Rao Model to Non-ergodic Type Processes -- 4. Mixture Experiments and Conditional Inference -- 5. Non-local Results -- 1. A General Model and Its Local Approximation -- 1. Introduction -- 2. LAMN Families -- 3. Consequences of the LAMN Condition -- 4. Sufficient Conditions for the LAMN Property -- 5. Asymptotic Sufficiency -- 6. An Example (Galton-Watson Branching Process) -- 7. Bibliographical Notes -- 2. Efficiency of Estimation -- 1. Introduction -- 2. Asymptotic Structure of Limit Distributions of Sequences of Estimators -- 3. An Upper Bound for the Concentration -- 4. The Existence and Optimality of the Maximum Likelihood Estimators -- 5. Optimality of Bayes Estimators -- 6. Bibliographical Notes -- 3. Optimal Asymptotic Tests -- 1. Introduction -- 2. The Optimality Criteria: Definitions -- 3. An Efficient Test of Simple Hypotheses: Contiguous Alternatives -- 4. Local Efficiency and Asymptotic Power of the Score Statistic -- 5. Asymptotic Power of the Likelihood Ratio Test: Simple Hypothesis -- 6. Asymptotic Powers of the Score and LR Statistics for Composite Hypotheses with Nuisance Parameters -- 7. An Efficient Test of Composite Hypotheses with Contiguous Alternatives -- 8. Examples -- 9. Bibliographical Notes -- 4. Mixture Experiments and Conditional Inference -- 1. Introduction -- 2. Mixture of Exponential Families -- 3. Some Examples -- 4. Efficient Conditional Tests with Reference to L -- 5. Efficient Conditional Tests with Reference to L? -- 6. Efficient Conditional Tests with Reference to LC: Bahadur Efficiency -- 7. Efficiency of Conditional Maximum Likelihood Estimators -- 8. Conditional Tests for Markov Sequences and Their Mixtures -- 9. Some Heuristic Remarks about Conditional Inference for the General Model -- 10. Bibliographical Notes -- 5. Some Non-local Results -- 1. Introduction -- 2. Non-local Behaviour of the Likelihood Ratio -- 3. Examples -- 4. Non-local Efficiency Results for Simple Likelihood Ratio Tests -- 5. Bibiographical Notes -- Appendices -- A.1 Uniform and Continuous Convergence -- A.2 Contiguity of Probability Measures -- References.
