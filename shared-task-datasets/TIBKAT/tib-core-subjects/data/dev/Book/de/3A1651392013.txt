Partitionierung zur effizienten Duplikaterkennung in relationalen Daten
Duplikate bzw. Dubletten sind mehrere Datensätze, die das gleiche Realweltobjekt beschreiben, etwa mehrfach erfasste Kunden in einem CRM-System oder unterschiedliche Repräsentationen eines Produkts. Das Auffinden dieser Duplikate ist auch für moderne Computer eine komplexe und zeitintensive Aufgabe. Uwe Draisbach vergleicht zwei der einschlägigen Partitionierungsstrategien, die eine intelligente Auswahl von zu vergleichenden Datensatzpaaren treffen. Daraus entwickelt er ein verallgemeinertes Verfahren und zeigt, dass eine intelligente Auswahl der Datensatzpaare den Aufwand signifikant reduzieren kann, ohne die Qualität der Duplikaterkennung wesentlich zu verringern. Die Arbeit wurde mit dem „Information Quality Best Master Degree Award“ der Deutschen Gesellschaft für Informations- und Datenqualität ausgezeichnet.
Duplikaterkennung -- Blocking-Verfahren -- Windowing-Verfahren -- Vergleich Blocking- und Sorted-Neighborhood-Methode -- Verallgemeinertes Verfahren.
