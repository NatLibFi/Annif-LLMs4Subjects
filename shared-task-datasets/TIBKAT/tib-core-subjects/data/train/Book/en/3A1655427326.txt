Fitting Linear Models : An Application of Conjugate Gradient Algorithms
1. Preliminaries -- 1.1 Introduction -- 1.2 Notation Used in This Thesis -- 2. The Linear Model -- 2.1 The Gaussian Linear Model -- 2.2 Specifying an Arbitrary Model -- 2.3 Effective Balance -- 2.4 The Generalized Linear Model -- 3. The Conjugate Gradient Algorithm -- 3.1 Minimization Concepts -- 3.2 The Basic Algorithm -- 3.3 Convergence Considerations -- 3.4 The Non-Full Rank Case -- 3.5 Computational Details -- 3.6 Preconditioning -- 4. Applications: The Non-Full Rank Case -- 4.1 A Direct Sum Decomposition -- 4.2 Enumeration of Eigenvalues -- 4.3 Complete Factorial Designs -- 4.4 Other Designs -- 4.5 Preconditioning -- 5. Applications: The Full Rank Case -- 5.1 A Full Rank Parameterization -- 5.2 Hierarchical Models -- 5.3 Eigenvalues for Complete Factorial Designs -- 5.4 Other Designs -- 5.5 Preconditioning -- 6. Examples: Gaussian Linear Models -- 6.1 Implementation Details -- 6.2 The General 3-Way Case -- 6.3 A Blocked 23 Experiment -- 6.4 A Fractional 34 Experiment -- 6.5 A Quasi Latin Square Example -- 6.6 A Balanced Incomplete Block Example -- 7. Examples: Generalized Linear Models -- 7.1 Implementation Details -- 7.2 A 3x24 Loglinear Model -- 7.3 22 Loglinear Model on a Latin Square -- 7.4 A 3x22 Binomial Example -- 7.5 A Combined Loglinear and Binomial Example -- 8. Concluding Remarks -- References -- Appendices -- A. Algorithms -- A.I Hestenes-Stiefel Algorithm -- A.2 Beale Algorithm -- A.3 Preconditioned Hestenes-Stiefel Algorithm -- A.4 Hemmerle’s Algorithm with Line Search; -- A.5 Hestenes-Stiefel Algorithm with Hemmerle’s Preconditioning -- A.6 Eigenvalues, Non-Full Rank Parameterization -- A.7 Eigenvalues, Full Rank Parameterization -- B. GLIM Output.
The increasing power and decreasing price of smalI computers, especialIy "personal" computers, has made them increasingly popular in statistical analysis. The day may not be too far off when every statistician has on his or her desktop computing power on a par with the large mainframe computers of 15 or 20 years ago. These same factors make it relatively easy to acquire and manipulate large quantities of data, and statisticians can expect a corresponding increase in the size of the datasets that they must analyze. Unfortunately, because of constraints imposed by architecture, size or price, these smalI computers do not possess the main memory of their large cousins. Thus, there is a growing need for algorithms that are sufficiently economical of space to permit statistical analysis on smalI computers. One area of analysis where there is a need for algorithms that are economical of space is in the fitting of linear models.
