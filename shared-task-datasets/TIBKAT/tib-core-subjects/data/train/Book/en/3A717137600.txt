Data-intensive computing : architectures, algorithms, and applications
"A Challenge for the 21st Century Introduction In a world of rapid technological change such as the one we inhabit, it's occasionally instructive to contemplate how much things have changed in the last few years. For many, remembering life without the ability to view the World Wide Web (WWW) through the windows of a browser will be difficult (if not impossible for less 'mature' readers). And is it only seven years since YouTube, a Web site that is ingrained in so many facets of modern life, first came to life? How did we all really survive without FaceBook all those (actually, about 5) years ago? Various estimates put the amount of data stored by consumers and businesses around the world in 2010 in the vicinity of 13 exabytes, with a growth rate of 20--25% per annum. That's a lot of data. No wonder IBM is pursuing building a 120 petabyte storage array . There's obviously going to be a market for such devices in the future. As data volumes of all types, from video and photos to text documents and binary files for science, continue to grow in number and resolution, it's clear we have genuinely entered the realm of data intensive, or big data , computing."--
"A reference describing the general principles of the emerging field of data-intensive computing, along with methods for designing, managing and analyzing the big data sets of today"--
