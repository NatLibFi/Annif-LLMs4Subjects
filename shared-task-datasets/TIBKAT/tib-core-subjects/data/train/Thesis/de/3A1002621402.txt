Probabilistic models for invariant representations and transformations
Diese Arbeit beschäftigt sich mit Daten-Modellen des Maschinellen Lernens, die invariante Repräsentationen und Repräsentationen von Transformationen zur Verfügung stellen. Der erste hier behandelte Algorithmus basiert auf einem Sparse Coding Modell mit diskreten Koeffizienten. Der darauf folgende Algorithmus erweitert den diskreten Sparse Coding Ansatz um eindimensionale Datenpunkt-Transformationen adressieren zu können. Des Weiteren wird ein Neuronales Netzwerk für Bild-Transformationen vorgeschlagen und analysiert. Schließlich wird ein Modell in der Form eines nicht-linearen dynamischen Systems untersucht, was zwischen verschiedenen Transformationen zu verschiedenen Zeiten separieren kann. Die hier erwähnten Algorithmen werden experimentell auf synthetischen und reellen Daten evaluiert, um ihre Effektivität und allgemeine Anwendbarkeit zu quantifizieren. <dt.>
This thesis deals with machine learning models that either provide invariant representations for data or provide representations for transformations in the dataset. The first algorithm proposed is based on a sparse coding model with discrete coefficients. The following algorithm, extends the discrete sparse coding method to deal with one dimensional translations. Furthermore, a Neural Network for image transformations is proposed and analyzed. Lastly, a nonlinear dynamical system designed to separate transformations at different points in time is introduced and discussed. For the most part the afore mentioned algorithms are experimentally evaluated on synthetic and real data to quantify effectiveness and general applicability. <engl.>
