Robust automatic speech recognition and modeling of auditory discrimination experiments with auditory spectro-temporal features
Automatic speech recognition (ASR) systems still do not perform as well as human listeners under realistic conditions. The unmatched ability of humans to understand speech in most difficult acoustic conditions originates from the superior properties of their auditory system. The aim of this thesis is to improve the recognition performance of ASR systems in difficult acoustic conditions by carefully integrating auditory signal processing strategies. To this end, the physiologically inspired extraction of spectro-temporal modulation patterns was successfully integrated into the front-end of a standard ASR system. Further, the joint spectro-temporal processing could be separated into independent temporal and spectral processes. To investigate the reason for the remaining "man-machine-gap" in recognition performance, a range of critical auditory discrimination tasks were performed using ASR systems. The comparison with empirical data showed that the separate spectro-temporal modulation front-end provides a suitable auditory model and revealed the importance of across-frequency processing in speech recognition. <engl.>
