High-dimensional function approximation : breaking the curse with Monte Carlo methods
In this dissertation we study the information-based complexity for high-dimensional function approximation problems. In the deterministic setting for many unweighted problems the curse of dimensionality holds, that means, for some fixed error tolerance the complexity grows exponentially with the dimension. For integration problems one can usually break the curse with the standard Monte Carlo method. For function approximation problems, however, similar effects of randomization have been unknown so far. The thesis contains results on three more or less stand-alone topics. Chapter 2 is concerned with lower bounds for the Monte Carlo error for general linear problems via Bernstein numbers. This technique is applied to the uniform approximation of certain classes of smooth functions, where it turns out that randomization does not affect the tractability classification of the problem. Chapter 3 studies the uniform approximation of functions from Hilbert spaces with methods that may use arbitrary linear functionals as information. For certain unweighted periodic tensor product spaces, in particular Korobov spaces, we observe the curse of dimensionality in the deterministic setting, whereas with randomized methods we achieve polynomial tractability. Chapter 4 deals with the approximation of monotone functions via function values. It is known that this problem suffers from the curse of dimensionality in the deterministic setting. A new upper bound shows that Monte Carlo methods do break the curse. Almost matching lower bounds are found as well, from which follows that randomization will not help significantly for small error tolerances.
